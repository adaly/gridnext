{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('../src/')\n",
    "from training import train_spotwise, train_gridwise\n",
    "from count_datasets import load_count_dataset, load_count_grid_dataset, read_annotated_starray\n",
    "from count_datasets import CountDataset, CountGridDataset\n",
    "\n",
    "from scanpy.pp import highly_variable_genes\n",
    "from anndata import AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adaly/opt/anaconda3/lib/python3.7/site-packages/anndata/_core/anndata.py:119: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Find highly variable genes according to the method of Seurat_V3, which operates on (raw) count data.\n",
    "# - z-score normalization performed per feature (gene)\n",
    "# - calculate variance of each gene after normalization, return genes w/highest values\n",
    "\n",
    "data_dir = os.path.expanduser('~/Documents/Splotch_projects/Maynard_DLPFC/data/')\n",
    "\n",
    "X = []\n",
    "files, coords = [],[]\n",
    "\n",
    "for cfile in glob.glob(os.path.join(data_dir, 'Countfiles_Visium', '*.unified.tsv')):\n",
    "    count_dat = pd.read_csv(cfile, sep='\\t', header=0, index_col=0)\n",
    "    X.append(count_dat.values.T)\n",
    "    \n",
    "    coords += list(count_dat.columns)\n",
    "    files += [Path(cfile).name] * len(count_dat.columns)\n",
    "X = np.vstack(X)\n",
    "\n",
    "var = pd.DataFrame(index=count_dat.index)\n",
    "obs = pd.DataFrame({'st_file': files, 'st_coord': coords})\n",
    "\n",
    "adata = AnnData(X, obs=obs, var=var)\n",
    "\n",
    "highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=2150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which of Joana's marker genes are included in the set of automatically-derived HVGs\n",
    "jp_markers = {\n",
    "    'MBP': 'ENSG00000197971',    # WM\n",
    "    'SNAP25': 'ENSG00000132639', # GM (Layers 1-6)\n",
    "    'PCP4': 'ENSG00000183036',   # Layer 5\n",
    "    'RORB': 'ENSG00000198963',   # Layer 4\n",
    "    'SYNPR': 'ENSG00000163630',  # Layer 6\n",
    "    'MFGE8': 'ENSG00000140545',\n",
    "    'CBLN2': 'ENSG00000141668',\n",
    "    'RPRM': 'ENSG00000177519',\n",
    "    'NR4A2': 'ENSG00000153234',\n",
    "    'CXCL14': 'ENSG00000145824',\n",
    "    'C1QL2': 'ENSG00000144119',\n",
    "    'CUX2': 'ENSG00000111249',\n",
    "    'CARTPT': 'ENSG00000164326',\n",
    "    'CCK': 'ENSG00000187094'\n",
    "}\n",
    "\n",
    "for key, val in jp_markers.items():\n",
    "    if not adata.var.loc[val, 'highly_variable']:\n",
    "        print(key, \"is not a HVG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvgs = adata.var.index[adata.var['highly_variable']]\n",
    "\n",
    "train_tissues = ['151507', '151508', '151509', '151510', '151669', '151670', '151671', '151672', '151673', '151674']\n",
    "val_tissues = ['151675', '151676']\n",
    "\n",
    "countfiles_train = [os.path.join(data_dir, 'Countfiles_Visium_norm/%s_stdata_aligned_counts_IDs.txt.unified.tsv') % s for s in train_tissues]\n",
    "annotfiles_train = [os.path.join(data_dir, 'Covariates_Visium/%s.tsv') % s for s in train_tissues]\n",
    "\n",
    "countfiles_val = [os.path.join(data_dir, 'Countfiles_Visium_norm/%s_stdata_aligned_counts_IDs.txt.unified.tsv') % s for s in val_tissues]\n",
    "annotfiles_val = [os.path.join(data_dir, 'Covariates_Visium/%s.tsv') % s for s in val_tissues]\n",
    "\n",
    "# Load full datasets into memory for quick training\n",
    "train_spot_hvg = load_count_dataset(countfiles_train, annotfiles_train, select_genes=hvgs)\n",
    "val_spot_hvg = load_count_dataset(countfiles_val, annotfiles_val, select_genes=hvgs)\n",
    "\n",
    "dataloader_spot_hvg = {\n",
    "    'train': DataLoader(train_spot_hvg, batch_size=32, shuffle=True),\n",
    "    'val': DataLoader(val_spot_hvg, batch_size=32)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.9304 Acc: 0.7082\n",
      "val Loss: 0.8225 Acc: 0.6989\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.5943 Acc: 0.7876\n",
      "val Loss: 0.7726 Acc: 0.7069\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.4899 Acc: 0.8205\n",
      "val Loss: 0.8572 Acc: 0.6922\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.4028 Acc: 0.8565\n",
      "val Loss: 0.8202 Acc: 0.7084\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.3074 Acc: 0.8960\n",
      "val Loss: 0.8737 Acc: 0.6947\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.2254 Acc: 0.9303\n",
      "val Loss: 1.0032 Acc: 0.6686\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.1649 Acc: 0.9523\n",
      "val Loss: 1.2598 Acc: 0.6660\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.1241 Acc: 0.9645\n",
      "val Loss: 1.0933 Acc: 0.6740\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.1021 Acc: 0.9707\n",
      "val Loss: 1.3312 Acc: 0.6683\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.0882 Acc: 0.9737\n",
      "val Loss: 1.4349 Acc: 0.6537\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.0774 Acc: 0.9768\n",
      "val Loss: 1.4468 Acc: 0.6627\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.0692 Acc: 0.9785\n",
      "val Loss: 1.5072 Acc: 0.6693\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.0606 Acc: 0.9814\n",
      "val Loss: 1.5224 Acc: 0.6559\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.0585 Acc: 0.9824\n",
      "val Loss: 1.6579 Acc: 0.6536\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.0586 Acc: 0.9814\n",
      "val Loss: 1.6606 Acc: 0.6653\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.0533 Acc: 0.9834\n",
      "val Loss: 1.5840 Acc: 0.6580\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.0472 Acc: 0.9856\n",
      "val Loss: 1.5777 Acc: 0.6636\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.0451 Acc: 0.9861\n",
      "val Loss: 1.6856 Acc: 0.6614\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.0448 Acc: 0.9853\n",
      "val Loss: 1.7305 Acc: 0.6583\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.0463 Acc: 0.9852\n",
      "val Loss: 1.6634 Acc: 0.6639\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.0411 Acc: 0.9865\n",
      "val Loss: 1.9081 Acc: 0.6488\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.0394 Acc: 0.9874\n",
      "val Loss: 1.8521 Acc: 0.6493\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.0360 Acc: 0.9878\n",
      "val Loss: 1.8477 Acc: 0.6448\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.0379 Acc: 0.9876\n",
      "val Loss: 1.9679 Acc: 0.6484\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.0333 Acc: 0.9891\n",
      "val Loss: 1.8188 Acc: 0.6609\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.0327 Acc: 0.9894\n",
      "val Loss: 2.1213 Acc: 0.6406\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.0320 Acc: 0.9896\n",
      "val Loss: 1.9130 Acc: 0.6586\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.9901\n",
      "val Loss: 1.9590 Acc: 0.6540\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.0328 Acc: 0.9896\n",
      "val Loss: 2.1979 Acc: 0.6500\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.0362 Acc: 0.9880\n",
      "val Loss: 1.8408 Acc: 0.6553\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.0254 Acc: 0.9919\n",
      "val Loss: 2.0425 Acc: 0.6433\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.0332 Acc: 0.9886\n",
      "val Loss: 1.9628 Acc: 0.6497\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.0312 Acc: 0.9897\n",
      "val Loss: 1.9705 Acc: 0.6627\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.0269 Acc: 0.9909\n",
      "val Loss: 2.0121 Acc: 0.6544\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.0275 Acc: 0.9911\n",
      "val Loss: 1.9875 Acc: 0.6560\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.0271 Acc: 0.9911\n",
      "val Loss: 2.1682 Acc: 0.6506\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.0270 Acc: 0.9912\n",
      "val Loss: 2.0588 Acc: 0.6517\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.0263 Acc: 0.9911\n",
      "val Loss: 2.0224 Acc: 0.6584\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.0215 Acc: 0.9930\n",
      "val Loss: 2.2791 Acc: 0.6477\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.0256 Acc: 0.9914\n",
      "val Loss: 2.3446 Acc: 0.6416\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.0252 Acc: 0.9914\n",
      "val Loss: 2.1747 Acc: 0.6621\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.0219 Acc: 0.9926\n",
      "val Loss: 2.2093 Acc: 0.6517\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.0235 Acc: 0.9921\n",
      "val Loss: 2.1941 Acc: 0.6521\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.0258 Acc: 0.9913\n",
      "val Loss: 2.2204 Acc: 0.6540\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.0210 Acc: 0.9929\n",
      "val Loss: 2.2181 Acc: 0.6611\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.0261 Acc: 0.9909\n",
      "val Loss: 2.1595 Acc: 0.6483\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.0235 Acc: 0.9917\n",
      "val Loss: 2.1433 Acc: 0.6647\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.0226 Acc: 0.9924\n",
      "val Loss: 2.2430 Acc: 0.6581\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.0211 Acc: 0.9933\n",
      "val Loss: 2.2731 Acc: 0.6553\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.0209 Acc: 0.9931\n",
      "val Loss: 2.2432 Acc: 0.6487\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.0189 Acc: 0.9940\n",
      "val Loss: 2.2155 Acc: 0.6570\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.0191 Acc: 0.9940\n",
      "val Loss: 2.3878 Acc: 0.6377\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.0207 Acc: 0.9930\n",
      "val Loss: 2.4767 Acc: 0.6394\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.0203 Acc: 0.9933\n",
      "val Loss: 2.2253 Acc: 0.6500\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.0184 Acc: 0.9936\n",
      "val Loss: 2.2721 Acc: 0.6581\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.0174 Acc: 0.9940\n",
      "val Loss: 2.1699 Acc: 0.6556\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.0192 Acc: 0.9936\n",
      "val Loss: 2.1647 Acc: 0.6567\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.0202 Acc: 0.9933\n",
      "val Loss: 2.2537 Acc: 0.6610\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.0188 Acc: 0.9939\n",
      "val Loss: 2.2207 Acc: 0.6620\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.0176 Acc: 0.9942\n",
      "val Loss: 2.3927 Acc: 0.6444\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.0205 Acc: 0.9927\n",
      "val Loss: 2.2636 Acc: 0.6609\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.0175 Acc: 0.9942\n",
      "val Loss: 2.3525 Acc: 0.6591\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.0151 Acc: 0.9951\n",
      "val Loss: 2.2318 Acc: 0.6514\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.0159 Acc: 0.9946\n",
      "val Loss: 2.4356 Acc: 0.6474\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.0153 Acc: 0.9948\n",
      "val Loss: 2.4409 Acc: 0.6468\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.0162 Acc: 0.9942\n",
      "val Loss: 2.3298 Acc: 0.6551\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.0161 Acc: 0.9946\n",
      "val Loss: 2.3663 Acc: 0.6581\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.0157 Acc: 0.9947\n",
      "val Loss: 2.3954 Acc: 0.6501\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.0178 Acc: 0.9938\n",
      "val Loss: 2.7680 Acc: 0.6323\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.0159 Acc: 0.9947\n",
      "val Loss: 2.4669 Acc: 0.6509\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.0156 Acc: 0.9946\n",
      "val Loss: 2.2981 Acc: 0.6614\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.0150 Acc: 0.9948\n",
      "val Loss: 2.5737 Acc: 0.6437\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9951\n",
      "val Loss: 2.4396 Acc: 0.6539\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.0164 Acc: 0.9941\n",
      "val Loss: 2.3795 Acc: 0.6517\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9952\n",
      "val Loss: 2.3668 Acc: 0.6513\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.0165 Acc: 0.9939\n",
      "val Loss: 2.3063 Acc: 0.6553\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.0152 Acc: 0.9950\n",
      "val Loss: 2.4484 Acc: 0.6490\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.0149 Acc: 0.9950\n",
      "val Loss: 2.5056 Acc: 0.6541\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.0139 Acc: 0.9951\n",
      "val Loss: 2.6071 Acc: 0.6456\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.0143 Acc: 0.9952\n",
      "val Loss: 2.5517 Acc: 0.6537\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.0138 Acc: 0.9952\n",
      "val Loss: 2.5437 Acc: 0.6421\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.0149 Acc: 0.9955\n",
      "val Loss: 2.5355 Acc: 0.6457\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.0123 Acc: 0.9960\n",
      "val Loss: 2.4699 Acc: 0.6450\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 0.9956\n",
      "val Loss: 2.6066 Acc: 0.6428\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 0.9954\n",
      "val Loss: 2.5115 Acc: 0.6453\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.0149 Acc: 0.9948\n",
      "val Loss: 2.4914 Acc: 0.6470\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.0139 Acc: 0.9952\n",
      "val Loss: 2.4619 Acc: 0.6549\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.0121 Acc: 0.9959\n",
      "val Loss: 2.6101 Acc: 0.6474\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.0145 Acc: 0.9950\n",
      "val Loss: 2.5958 Acc: 0.6478\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.0130 Acc: 0.9958\n",
      "val Loss: 2.5870 Acc: 0.6461\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.0120 Acc: 0.9961\n",
      "val Loss: 2.4467 Acc: 0.6609\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.0138 Acc: 0.9955\n",
      "val Loss: 2.5929 Acc: 0.6517\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.0124 Acc: 0.9959\n",
      "val Loss: 2.4608 Acc: 0.6513\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.0117 Acc: 0.9959\n",
      "val Loss: 2.6668 Acc: 0.6490\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.0114 Acc: 0.9961\n",
      "val Loss: 2.7487 Acc: 0.6427\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.0129 Acc: 0.9956\n",
      "val Loss: 2.6479 Acc: 0.6496\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.0131 Acc: 0.9958\n",
      "val Loss: 2.3799 Acc: 0.6550\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.0128 Acc: 0.9961\n",
      "val Loss: 2.4089 Acc: 0.6557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 98/99\n",
      "----------\n",
      "train Loss: 0.0115 Acc: 0.9961\n",
      "val Loss: 2.5235 Acc: 0.6478\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.0123 Acc: 0.9964\n",
      "val Loss: 2.7206 Acc: 0.6346\n",
      "\n",
      "Training complete in 12m 50s\n",
      "Best val Acc: 0.708446\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbd09a7f890>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit a basic fully-connected network to the top 2150 HVGs\n",
    "df = pd.read_csv(annotfiles_train[0], header=0, index_col=0, sep='\\t')\n",
    "annot_names = list(df.index.values)\n",
    "\n",
    "spot_clf_hvg = nn.Sequential(\n",
    "    nn.Linear(len(hvgs), 500),\n",
    "    nn.Linear(500, 100),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(100, 100),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    nn.Linear(50, len(annot_names))\n",
    ")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(spot_clf_hvg.parameters(), lr=1e-4)\n",
    "\n",
    "spot_clf_hvg, val_hist, train_hist = train_spotwise(spot_clf_hvg, dataloader_spot_hvg, loss, optimizer, 100, \n",
    "                                                    display=False, outfile='../models/spot_classifier_hvg.pth')\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_hist, label='train')\n",
    "plt.plot(val_hist, label='val')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
