{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2542a62-695c-44c4-81ba-2b836a1ee235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from gridnext.gridnet_models import GridNetHexOddr\n",
    "from gridnext.visium_datasets import create_visium_dataset, create_visium_anndata\n",
    "from gridnext.count_datasets import anndata_to_tensordataset, anndata_arrays_to_tensordataset\n",
    "from gridnext.training import train_spotwise, train_gridwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb736f4-e4a2-4e72-a6e9-2e174647d337",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/BA44_testdata'\n",
    "\n",
    "# TODO: instructions for downloading example data from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c916908-3a1b-4245-b3d1-f061f8e11dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceranger_dirs = sorted(glob.glob(os.path.join(data_dir, 'spaceranger', '*')))\n",
    "annot_files = sorted(glob.glob(os.path.join(data_dir, 'annotations', '*.csv')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdcf9a8-3a0b-4084-9222-d58293108ec3",
   "metadata": {},
   "source": [
    "### 1.1 Load spot data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d21f6b5-c5cd-4cb9-9f47-507d585a3d88",
   "metadata": {},
   "source": [
    "### a) Load large dataset (low memory usage, slow accession)\n",
    "Map-style PyTorch dataset for lazy loading of spots from large datasets. Use when full data cannot fit into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8299e87-fee0-46ec-824e-38ceb1b0d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920 un-annotated spots\n",
      "228 un-annotated spots\n",
      "1692 un-annotated spots\n",
      "19540 training and 2548 validation spots\n",
      "7 classes\n"
     ]
    }
   ],
   "source": [
    "# First, create a CountDataset using all arrays to generate unified countfiles:\n",
    "# (once this has been done once, you can skip straight to train/test set creation)\n",
    "pdat = create_visium_dataset(spaceranger_dirs, annot_files=annot_files, \n",
    "                             use_count=True, use_image=False, spatial=False)\n",
    "\n",
    "# Create training and validation datasets\n",
    "n_val = 1\n",
    "train_srd = spaceranger_dirs[n_val:]\n",
    "train_ann = annot_files[n_val:]\n",
    "\n",
    "val_srd = spaceranger_dirs[:n_val]\n",
    "val_ann = annot_files[:n_val]\n",
    "\n",
    "train_pdat = create_visium_dataset(train_srd, annot_files=train_ann,\n",
    "                                   use_count=True, use_image=False, spatial=False)\n",
    "val_pdat = create_visium_dataset(val_srd, annot_files=val_ann,\n",
    "                                 use_count=True, use_image=False, spatial=False)\n",
    "print('%d training and %d validation spots' % (len(train_pdat), len(val_pdat)))\n",
    "\n",
    "assert np.array_equal(train_pdat.classes, val_pdat.classes), \"Classes in train/val data do not match!\"\n",
    "class_names = train_pdat.classes\n",
    "print('%d classes' % len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e67899-e3c2-461b-9ea1-8f4f50336954",
   "metadata": {},
   "source": [
    "### b) Load small dataset (high memory usage, fast accession)\n",
    "Load full dataset into memory for fast accession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a32b59ad-bf57-4bbe-8451-31f66db842c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create AnnData representation of full Visium data (all arrays)\n",
    "destfile = os.path.join(data_dir, 'adata_tutorial.h5ad')\n",
    "\n",
    "#adata = create_visium_anndata(spaceranger_dirs, annot_files=annot_files, destfile=destfile)\n",
    "# Use for future accession after running previous line once:\n",
    "adata = ad.read_h5ad(destfile)  # add \"backed='r'\" to avoid reading full AnnData into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ebccd8-07c1-426b-b03e-0c415342195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2y/rfyy59b10y1bdnyzxhgdcf9w0000gn/T/ipykernel_52658/2943881343.py:6: RuntimeWarning: invalid value encountered in divide\n",
      "  cvar = np.abs(adata.X.std(axis=0) / adata.X.mean(axis=0))\n"
     ]
    }
   ],
   "source": [
    "# Perform desired preprocessing (normalization, log-transform, HVG selection, etc...)\n",
    "sc.pp.normalize_total(adata, 1e4)\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "n_hvgs = 2000\n",
    "cvar = np.abs(adata.X.std(axis=0) / adata.X.mean(axis=0))\n",
    "cvar[adata.X.mean(axis=0) == 0] = 0  # disregard genes with 0 mean as HVGs\n",
    "thresh_val = np.sort(cvar)[-n_hvgs]\n",
    "adata = adata[:, cvar >= thresh_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2907f05c-cd1a-4d39-afbc-1ee50dd124bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19540 training and 2548 validation spots\n",
      "7 classes\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation datasets\n",
    "n_val = 1\n",
    "val_arrays = adata.obs.array.unique()[:n_val]\n",
    "train_arrays = adata.obs.array.unique()[n_val:]\n",
    "adata_val = adata[adata.obs.array.isin(val_arrays)]\n",
    "adata_train = adata[adata.obs.array.isin(train_arrays)]\n",
    "\n",
    "train_pdat, train_classes  = anndata_to_tensordataset(adata_train, 'annotation')\n",
    "val_pdat, val_classes = anndata_to_tensordataset(adata_val, 'annotation')\n",
    "print('%d training and %d validation spots' % (len(train_pdat), len(val_pdat)))\n",
    "\n",
    "assert np.array_equal(train_classes, val_classes), \"Classes in train/val data do not match!\"\n",
    "class_names = train_classes\n",
    "print('%d classes' % len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73f034a-9cb9-47ff-b9f7-7bbe9e675311",
   "metadata": {},
   "source": [
    "### 1.2. Train spot classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7162b32-aace-48cc-aba7-4626bf0e2947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training loop\n",
    "dataloader_spots = {\n",
    "    'train': DataLoader(train_pdat, batch_size=128, shuffle=True),\n",
    "    'val': DataLoader(val_pdat, batch_size=128)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5face872-d0fe-40a0-992e-75d47efb56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate fully-connected network to be used as spot classifier (f)\n",
    "x, _ = train_pdat[0]\n",
    "input_size = x.shape[0]\n",
    "\n",
    "f = nn.Sequential(\n",
    "    nn.Linear(input_size, 500),\n",
    "    nn.Linear(500, 100),\n",
    "    nn.BatchNorm1d(100),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(100, 100),\n",
    "    nn.Linear(100, 50),\n",
    "    nn.BatchNorm1d(50),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Linear(50, len(class_names))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bc030fd-aebc-4050-97a3-2245f4baa2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 1.9473 Acc: 0.2692\n",
      "val Loss: 1.9068 Acc: 0.3206\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 1.7212 Acc: 0.3662\n",
      "val Loss: 1.9032 Acc: 0.3257\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 1.5985 Acc: 0.3854\n",
      "val Loss: 1.9400 Acc: 0.3277\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 1.5220 Acc: 0.3908\n",
      "val Loss: 1.9986 Acc: 0.3289\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 1.4742 Acc: 0.3946\n",
      "val Loss: 2.0482 Acc: 0.3285\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 1.4407 Acc: 0.3951\n",
      "val Loss: 2.0861 Acc: 0.3281\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 1.4170 Acc: 0.3961\n",
      "val Loss: 2.1462 Acc: 0.3277\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 1.4017 Acc: 0.3964\n",
      "val Loss: 2.1860 Acc: 0.3269\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 1.3903 Acc: 0.3960\n",
      "val Loss: 2.2122 Acc: 0.3250\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 1.3801 Acc: 0.3983\n",
      "val Loss: 2.2560 Acc: 0.3285\n",
      "\n",
      "Training complete in 0m 24s\n",
      "Best val loss: 1.903159\n"
     ]
    }
   ],
   "source": [
    "# Perform model training and save parameters\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(f.parameters(), lr=1e-4)\n",
    "\n",
    "output_dir = '../models'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "outfile = os.path.join(output_dir, 'tutorial_f_count.pth')\n",
    "\n",
    "f, f_val_hist, f_train_hist = train_spotwise(f, dataloader_spots, loss, optimizer, \n",
    "                                             num_epochs=10, display=False, outfile=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cfe0dd-3061-4b18-b8aa-5b1b0af33d90",
   "metadata": {},
   "source": [
    "### 2.1. Load grid data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f3e8e-c680-4f8a-9f04-a68c8fc7be9c",
   "metadata": {},
   "source": [
    "### a) Large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf8ae88-0219-4619-b8f5-e70f9f092af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 training and 1 validation arrays\n",
      "7 classes\n"
     ]
    }
   ],
   "source": [
    "# Create training and validation datasets\n",
    "train_gdat = create_visium_dataset(train_srd, annot_files=train_ann,\n",
    "                                   use_count=True, use_image=False, spatial=True)\n",
    "val_gdat = create_visium_dataset(val_srd, annot_files=val_ann,\n",
    "                                 use_count=True, use_image=False, spatial=True)\n",
    "print('%d training and %d validation arrays' % (len(train_gdat), len(val_gdat)))\n",
    "\n",
    "class_names = train_gdat.classes\n",
    "print('%d classes' % len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98463aa0-8089-43c2-949e-0c16b30c5938",
   "metadata": {},
   "source": [
    "### b) Small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5c0a3b1-7ffb-4f42-b4d2-9cf4414af337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [18:03<00:00, 216.72s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [01:30<00:00, 90.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 training and 1 validation grids\n",
      "7 classes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_pdat, train_classes = anndata_arrays_to_tensordataset(adata_train, 'annotation', 'array')\n",
    "val_pdat, val_classes = anndata_arrays_to_tensordataset(adata_val, 'annotation', 'array')\n",
    "print('%d training and %d validation grids' % (len(train_pdat), len(val_pdat)))\n",
    "\n",
    "assert np.array_equal(train_classes, val_classes), \"Classes in train/val data do not match!\"\n",
    "class_names = train_classes\n",
    "print('%d classes' % len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bf117e-4d2e-474a-a932-d3115688a083",
   "metadata": {},
   "source": [
    "### 2.2. Training spatial corrector network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c7ec0c8-de4a-4b52-a8db-7b04d940b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders for training loop\n",
    "dataloader_grids = {\n",
    "    'train': DataLoader(train_gdat, batch_size=1, shuffle=True),\n",
    "    'val': DataLoader(val_gdat, batch_size=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6a7d265-4f0e-4388-a9b5-7023c79f555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate g network\n",
    "H_VISIUM = 78\n",
    "W_VISIUM = 64\n",
    "\n",
    "g = GridNetHexOddr(f, (input_size,), (H_VISIUM, W_VISIUM), n_classes=len(class_names), use_bn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f4140d-0ac4-4608-95c9-4699293c1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train g network\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(g.corrector.parameters(), lr=1e-3)\n",
    "\n",
    "# Fixing the parameters of the patch classifier allows slightly faster training, even when only\n",
    "# optimizing the parameters of the corrector. \n",
    "for param in g.patch_classifier.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "outfile = os.path.join(output_dir, 'tutorial_g_count')\n",
    "\n",
    "g, g_val_hist, g_train_hist = train_gridwise(g, dataloader_grids, loss, optimizer, \n",
    "                                             num_epochs=10, outfile=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ba054-ea73-4507-b0f5-e77b251a0c72",
   "metadata": {},
   "source": [
    "### 3. Visualizing train/validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2389b-7a38-49a0-a606-40f63d461940",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
